<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="/src/styles.css">

    <!-- LaTeX -->
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
  </head>
  <body>
    <h1> Thesis 11 </h1>
    <div>
      <h1> The functional CLT (Donsker's invariance principle): Proof, Simulations </h1>
      <p>
        In probability theory the functional CLT, also known as Donsker's theorem or Donsker's invariance principle, is an extension of the central limit theorem,
        discussed in the <a href="/thesis/thesis2.html">second thesis</a>, for empirical distribution functions. In particular, the theorem states that
        an appropriately centered and scaled version of the empirical distribution function converges to te Gaussian proccess, which follows the normal distribution,
        discussed in the <a href="/thesis/thesis3.html">third thesis</a>.
        <br>
        Let \( X_2, X_3, ... \) be a sequence of <b> indipendent and identically distributed </b> random variables. We consider these variables with mean \( 0 \)
        and variance \( 1 \). Let \( S_n = \sum^n_{i=1} X_i \). We consider the stochastic process called "random walk" as \( S := (S_n)_{n \in \mathbb{N} }\)
        
        Let us now define the rescalated random walk, which equals the partial-sum process, by considering
        $$ W^{(n)} (t) := \frac{S_{\lfloor nt \rfloor}}{\sqrt{n}} \text{ , where } t \in [0, 1] $$
        The CTL asserts that \( W^{(n)}(1) \) converges in distribution to a <b> Gaussian random variable </b> \( W(1) \) as \( n \to \infty \). Donsker's invariance
        principle extends this convergence to the whole function:
        $$ W^{(n)} := (W^{(n)} (t))_{t \in [0, 1]} $$
        More precisely, Donsker's invariance principle states that the random function \( W^{(n)} \) converges in distributino to a <b> standard Brownian motion </b>.
      </p>

      <div style="display: flex; flex-wrap: wrap; align-content: center; align-items: center; flex-direction: column; margin-top: 50px">
        <p> Donsker's invariance principle for a simple random walk: </p>
        <img style="width: 400px;" src="/src/th11/Donskers_invariance_principle.gif">
      </div>

      <h3> Proof </h3>
      <p>
        Let's consider the proof for this theorem:
        <br>
        It is based on the idea that it's possible to embed the ranom variables in the same probability space as the Brownian motion. This ensures that the scaled partial
        sums resembles the behaviour of a Brownian motion, given the correct scale.
        We start with a Brownian motion \( Bm(t) \) and define a the stopping times \( T_n \). In these points, the brownian motion will intersect the
        horizontal inteher lines. Formally we consider the stopping times as the following:
        $$ T_1 = inf\{t: \| Bm(t) \| = 1 \} $$ $$ T_{i+1} = inf\{t > T_n : \| Bm(t) - Bm(T_n) \| = 1 \} $$
        where \( T_n \) is the stopping time.
        <br>
        We now embed with <b> Skorokhod embedding </b>. This asserts the existance of a stopping time \( T \) so that \( Bm(T) \) follows the law of a random variable
        where the expected value is 0 ( \( E[X] = 0 \) ) and the expected value of the squared variable is limited ( \( E[X^2] < \infty \) ),
        and \( E[T] = E[X^2] \). We can then consider \( X \) a real random variable with mean 0 and variance 1 and define \( T_1 \) such that \( E[T_1] = 1 \)
        and \( Bm(T_1) \) follows the same distribution as \( X \).
        We now define \( T^2_0 \) that follows the same rules as \( T_1 \): \( E[T^2_0] = 1 \) and \(Bm (T^2_0) \) follows the same distribution as \( X \).
        <br>
        Let's consider \( T_2 = T_1 = T^2_0 \), we know that \( E[T_2] = E[T_1] + E[T^2_0] = 2 \). It's possible to continue this process by definining a sequence of
        stopping times \( T_1 < T_2 < T_3 < ... < T_n \) such that \( S_n = Bm(T_n) \), meaning that the Brownian motion with stopping times \( T_n \) has the
        same distribution as the random walk described by \( S_n \).
        After rescaling the Brownian motion, the difference
        $$ \sqrt{n} ( \frac{B_{nt}}{\sqrt{n} - S^*_n} ) $$
        becomes negligible as \( n \) approaces infinity ( \( n \to \infty \)).
        This implies the convergence in distribution of the scaled empirical process to a standard Brownian bridge.
      </p>

      <div style="display: flex; flex-wrap: wrap; align-content: center; align-items: center; flex-direction: column; margin-top: 50px">
        <p> Example of defining stopping times for a SRW: </p>
        <img style="width: 450px" src="/src/th11/stoptime.png">
      </div>

      <p>
        A simulation of random walk can be seen in the <a href="/code/homework7/application.html"> homework 7</a>.
      </p>
    </div>
    
    <ol>
      <li class="bibl"> Notes from the statistics course lectures </li>
      <li class="bibl"> Brownian motion (n. d.). Retrieved from Wikipedia, <a class="bibl" href="https://en.wikipedia.org/wiki/Brownian_motion"> https://en.wikipedia.org/wiki/Brownian_motion </a> </li>
      <li class="bibl"> Donsker's theorem (n. d.). Retrieved from Wikipedia, <a class="bibl" href="https://en.wikipedia.org/wiki/Donsker%27s_theorem"> https://en.wikipedia.org/wiki/Donsker%27s_theorem </a> </li>
      <li class="bibl"> Donsker's invariance principle (n. d.). Retrieved from encyclopediaofmath, <a class="bibl" href="https://encyclopediaofmath.org/wiki/Donsker_invariance_principle"> https://encyclopediaofmath.org/wiki/Donsker_invariance_principle </a> </li>
      <li class="bibl"> Brownian Motion: A Crash Course (n. d.). Retrieved from Washington education, <a class="bibl" href="https://sites.math.washington.edu/~rohde/583/Lectures13_14.pdf"> https://sites.math.washington.edu/~rohde/583/Lectures13_14.pdf </a> </li>
    </ol>

    <p class="thesisSelector">
      <a class="selector" href="/thesis/thesis10.html"> Previous thesis </a>
      <a class="selector" href="/"> Home </a>
      <a class="selector" href="/thesis/thesis12.html"> Next thesis </a>
    </p>
  </body>
</html>