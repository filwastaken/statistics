<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" href="/src/styles.css">
    <!-- LaTeX -->
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
  </head>
  <body>
    <h1> Thesis 2 </h1>
    <div>
      <h1> The CLT meaning, proof and simulations </h1>
      <p>
        The <b> Central Limit Theorem </b> (CLT) is a theorem that describes the properties of a sample mean, with a large enough sample.
        In particular it states that, by taking a sufficiently large sample from a population, it's means will be normally distributed,
        even if the population isn't normally distributed.
        We can describe the normal distribution by the paramters of the distribution of the population. In particular, the mean of the sampling
        distirbution is the mean of the population: \( \mu_{\overline{x}} = \mu \). On the other hand, the standard deviation of the sampling
        distirbution is the standard deviation of the population divided by the square root of the sample size: \( \sigma_{\overline{x}} = \frac{\sigma}{\sqrt{n}} \).
        We can now describe the normal function on those variables:
        $$ \overline{X} \sim N(\mu, \frac{\sigma}{\sqrt{n}}) $$
        We can look for this behaviour with the following example, created in exercise. The distribution drawn below follows a Poisson process, as we can see from the image
        on the left. However, with a large enough sample, we can see the typical bell curve of the normal distribution. This is consequence of the central limit theorem (image on the right).
      </p>
      <div style="display: flex; justify-content: space-around; align-items: center; flex-direction: row; margin-top: 25px; margin-bottom: 25px;">
        <div style="width: 500px; margin-left: 2%">
          <img style="width: 100%" src="/src/th2/clt_low.png">
          <p> $$ N = 25, M = 20, \lambda = 25 $$ </p>
        </div>
        <div style="width: 500px; margin-right: 2%;">
          <img style="width: 100%" src="/src/th2/clt_high.png">
          <p> $$ N = 200, M = 500, \lambda = 15 $$ </p>
        </div>
      </div>

      <h4> Proof: </h4>
      <p>
        Let's now consider the proof for CLT.

        Let's define a sequence of indipendent and identically distributed random variable \( X_i \) for i between 1 and n, that have mean 0 and variance \( \sigma^2 \). Let
        $$ S_n = \sum_{i=1}^nX_i $$
        We can verify that:
        $$ \lim_{n \to \infty} P(\frac{S_n}{\sigma \sqrt{n}} \le x) = \Phi(x), -\infty < x < \infty $$

        The proof lies on defining \( Z_n = \frac{S_n}{\sigma \sqrt{n}} \). We will show that the MGF (Moment generating function) of this variable tends to be equal to the one of the normal distribution.
        The moment-generating function of a random variable is an alternative specification of its probability distribution. It provides an alternative way to analytical results instead of working directly
        with probability density functions or cumulative distribution functions.

        $$ M_{S_n} (t) = [M(t)]^n $$ and $$ M_{Z_n} (t) = [M(\frac{t}{\sigma \sqrt{n}})]^n $$
        We can expand \( M(s) \) as the following Taylor series: \( M(s) = M(0) + sM'(0) + \frac{1}{2}M''(0) + ... \).
        Considering that \( E(X) = 0 \), \( M'(0) = 0 \) and \( M''(0) = \sigma^2 \), we thus have:
        $$ M_{Z_n} (t) = (1 + \frac{t^2}{2n} + \epsilon_n)^n $$
        This is how  Euler's number is defined: therefore it holds true that
        $$ M_{Z_n} (t) \to e^\frac{t^2}{2} \text{  as  } n \to \infty $$
        where the last expression is the MGF of the standard nomral distribution, as we wanted to prove. 
        The CLT implies that as the sample size increases, the distribution of \( \overline{X_n} \) becomes closer to a normal distribution. This is a crucial result in statistics,
        allowing us to use the normal distribution for various statistical inferences.
      </p>
    </div>

    <ol>
      <li class="bibl"> Notes from the statistics course lectures </li>
      <li class="bibl"> Central Limit Theorem | Formula, Definition & Examples. (n. d.). In Scribbr, Retrieved from <a class="bibl" href="https://www.scribbr.com/statistics/central-limit-theorem/"> https://www.scribbr.com/statistics/central-limit-theorem/ </a> </a> </li>
      <li class="bibl"> Central Limit Theorem. (n.d.). In Wikipedia. Retrieved from <a class="bibl" href="https://en.wikipedia.org/wiki/Central_limit_theorem"> https://en.wikipedia.org/wiki/Central_limit_theorem </a> </li>
      <li class="bibl"> Rice, J. A., Mathematical Statistics and Data analysis, Duxbury Press, Belmont, CA (1995). Retrieved from <a class="bibl" href="https://sites.chemengr.ucsb.edu/~ceweb/courses/che132c/Proof_Central_Limit_Theorem.pdf"> https://sites.chemengr.ucsb.edu/~ceweb/courses/che132c/Proof_Central_Limit_Theorem.pdf </a> </li>
      <li class="bibl"> Moment Generating Function. (n.d.). In Wikipedia. Retrieved from <a class="bibl" href="https://en.wikipedia.org/wiki/Moment-generating_function"> https://en.wikipedia.org/wiki/Moment-generating_function </a> </li>
    </ol>

    <p class="thesisSelector">
      <a class="selector" href="/thesis/thesis1.html"> Previous thesis </a>
      <a class="selector" href="/"> Home </a>
      <a class="selector" href="/thesis/thesis3.html"> Next thesis </a>
    </p>
  </body>
</html>
